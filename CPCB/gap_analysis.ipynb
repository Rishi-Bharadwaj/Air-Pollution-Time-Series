{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ac17b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 564 files to process\n",
      "Using 23 worker processes\n",
      "Progress: 10/564 files processed\n",
      "Progress: 20/564 files processed\n",
      "Progress: 30/564 files processed\n",
      "Progress: 40/564 files processed\n",
      "Progress: 50/564 files processed\n",
      "Progress: 60/564 files processed\n",
      "Progress: 70/564 files processed\n",
      "Progress: 80/564 files processed\n",
      "Progress: 90/564 files processed\n",
      "Progress: 100/564 files processed\n",
      "Progress: 110/564 files processed\n",
      "Progress: 120/564 files processed\n",
      "Progress: 130/564 files processed\n",
      "Progress: 140/564 files processed\n",
      "Progress: 150/564 files processed\n",
      "Progress: 160/564 files processed\n",
      "Progress: 170/564 files processed\n",
      "Progress: 180/564 files processed\n",
      "Progress: 190/564 files processed\n",
      "Progress: 200/564 files processed\n",
      "Progress: 210/564 files processed\n",
      "Progress: 220/564 files processed\n",
      "Progress: 230/564 files processed\n",
      "Progress: 240/564 files processed\n",
      "Progress: 250/564 files processed\n",
      "Progress: 260/564 files processed\n",
      "Progress: 270/564 files processed\n",
      "Progress: 280/564 files processed\n",
      "Progress: 290/564 files processed\n",
      "Progress: 300/564 files processed\n",
      "Progress: 310/564 files processed\n",
      "Progress: 320/564 files processed\n",
      "Progress: 330/564 files processed\n",
      "Progress: 340/564 files processed\n",
      "Progress: 350/564 files processed\n",
      "Progress: 360/564 files processed\n",
      "Progress: 370/564 files processed\n",
      "Progress: 380/564 files processed\n",
      "Progress: 390/564 files processed\n",
      "Progress: 400/564 files processed\n",
      "Progress: 410/564 files processed\n",
      "Progress: 420/564 files processed\n",
      "Progress: 430/564 files processed\n",
      "Progress: 440/564 files processed\n",
      "Progress: 450/564 files processed\n",
      "Progress: 460/564 files processed\n",
      "Progress: 470/564 files processed\n",
      "Progress: 480/564 files processed\n",
      "Progress: 490/564 files processed\n",
      "Progress: 500/564 files processed\n",
      "Progress: 510/564 files processed\n",
      "Progress: 520/564 files processed\n",
      "Progress: 530/564 files processed\n",
      "Progress: 540/564 files processed\n",
      "Progress: 550/564 files processed\n",
      "Progress: 560/564 files processed\n",
      "Progress: 564/564 files processed\n",
      "\n",
      "Successfully processed 564 out of 564 files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "\n",
    "def num_gaps(df, features):\n",
    "    \"\"\"\n",
    "    Analyze gaps in time series data and categorize them by duration.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with datetime index\n",
    "    features: list of column names to analyze\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with gap statistics per feature\n",
    "    \"\"\"\n",
    "    # Define gap bins in hours\n",
    "    gap_bins = [0, 1, 4, 8, 24, 72, 168, 336, 720, 2160, 8760, np.inf]  # bin edges\n",
    "    gap_labels = ['<1hr', '1-4hr', '4-8hr', '8hr-1day', '1-3days', '3days-1week', \n",
    "                  '1-2weeks', '2weeks-1month', '1-3months', '3months-1year', '>1year']  # 11 labels for 12 edges\n",
    "    \n",
    "    gap_stats = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Find missing values\n",
    "        is_missing = df[feature].isna()\n",
    "        \n",
    "        # Calculate gap lengths\n",
    "        gap_lengths = []\n",
    "        current_gap = 0\n",
    "        \n",
    "        for missing in is_missing:\n",
    "            if missing:\n",
    "                current_gap += 1\n",
    "            else:\n",
    "                if current_gap > 0:\n",
    "                    gap_lengths.append(current_gap)\n",
    "                    current_gap = 0\n",
    "        \n",
    "        # Add final gap if exists\n",
    "        if current_gap > 0:\n",
    "            gap_lengths.append(current_gap)\n",
    "        \n",
    "        # Categorize gaps into bins\n",
    "        if len(gap_lengths) > 0:\n",
    "            gap_counts = pd.cut(gap_lengths, bins=gap_bins, labels=gap_labels, right=False).value_counts().sort_index()\n",
    "            gap_stats[feature] = {\n",
    "                'total_gaps': len(gap_lengths),\n",
    "                'total_missing': is_missing.sum(),\n",
    "                'pct_missing': (is_missing.sum() / len(df)) * 100,\n",
    "                'gap_distribution': gap_counts.to_dict()\n",
    "            }\n",
    "        else:\n",
    "            gap_stats[feature] = {\n",
    "                'total_gaps': 0,\n",
    "                'total_missing': 0,\n",
    "                'pct_missing': 0.0,\n",
    "                'gap_distribution': {}\n",
    "            }\n",
    "    \n",
    "    return gap_stats\n",
    "\n",
    "\n",
    "def process_single_file(file, folder, features):\n",
    "    \"\"\"\n",
    "    Process a single file - worker function for parallel processing.\n",
    "    \n",
    "    Parameters:\n",
    "    file: filename to process\n",
    "    folder: path to folder containing the file\n",
    "    features: list of features to analyze\n",
    "    \n",
    "    Returns:\n",
    "    Tuple of (filename, gap_stats_dict) or (filename, None) on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(join(folder, file))\n",
    "        df = df.set_index('Timestamp')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Reindex to full hourly range from 2023 to 2025\n",
    "        full_range = pd.date_range(start='2023-01-01 00:00:00', \n",
    "                                  end='2025-12-31 23:00:00', \n",
    "                                  freq='1h')\n",
    "        df = df.reindex(full_range)\n",
    "        \n",
    "        # Analyze gaps\n",
    "        gaps = num_gaps(df, features)\n",
    "        return (file, gaps)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        return (file, None)\n",
    "\n",
    "\n",
    "def analyze_all_sites(folder, max_workers=None):\n",
    "    \"\"\"\n",
    "    Analyze gaps for all site files in the folder using concurrent.futures.\n",
    "    \n",
    "    Parameters:\n",
    "    folder: path to folder containing site CSV files\n",
    "    max_workers: maximum number of worker processes (default: CPU count - 1)\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with gap analysis for each site\n",
    "    \"\"\"\n",
    "    features = [\"PM2.5 (µg/m³)\", \"PM10 (µg/m³)\", \"NO2 (µg/m³)\", \"SO2 (µg/m³)\", \n",
    "                \"CO (mg/m³)\", \"Ozone (µg/m³)\", \"NH3 (µg/m³)\", \"AT (°C)\", \"RH (%)\"]\n",
    "    \n",
    "    # Get all CSV files in folder\n",
    "    files = [file for file in os.listdir(folder) if os.path.isfile(join(folder, file)) and file.endswith('.csv')]\n",
    "    \n",
    "    print(f\"Found {len(files)} files to process\")\n",
    "    \n",
    "    # Determine number of workers\n",
    "    if max_workers is None:\n",
    "        max_workers = max(1, os.cpu_count() - 1)\n",
    "    \n",
    "    print(f\"Using {max_workers} worker processes\")\n",
    "    \n",
    "    # Create partial function with fixed folder and features\n",
    "    worker = partial(process_single_file, folder=folder, features=features)\n",
    "    \n",
    "    # Process files in parallel\n",
    "    site_dict = {}\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_file = {executor.submit(worker, file): file for file in files}\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_file):\n",
    "            file, gaps = future.result()\n",
    "            if gaps is not None:\n",
    "                site_dict[file] = gaps\n",
    "            completed += 1\n",
    "            if completed % 10 == 0 or completed == len(files):\n",
    "                print(f\"Progress: {completed}/{len(files)} files processed\")\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed {len(site_dict)} out of {len(files)} files\")\n",
    "    \n",
    "    # Sort site_dict by site name\n",
    "    site_dict = dict(sorted(site_dict.items()))\n",
    "    \n",
    "    return site_dict\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "folder = r\"/home/rishi/ML Projects/Air Pollution/CPCB/sites_comb\"\n",
    "results = analyze_all_sites(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6028c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sites analyzed: 564\n",
      "\n",
      "Summary of missing data:\n",
      "                                              Site        Feature  Total Gaps  \\\n",
      "0   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv  PM2.5 (µg/m³)         128   \n",
      "1   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv   PM10 (µg/m³)         132   \n",
      "2   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv    NO2 (µg/m³)         119   \n",
      "3   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv    SO2 (µg/m³)           1   \n",
      "4   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv     CO (mg/m³)         111   \n",
      "5   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv  Ozone (µg/m³)         126   \n",
      "6   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv    NH3 (µg/m³)           1   \n",
      "7   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv        AT (°C)           1   \n",
      "8   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv         RH (%)           1   \n",
      "9     site_104_Burari_Crossing_Delhi_IMD_15Min.csv  PM2.5 (µg/m³)         166   \n",
      "10    site_104_Burari_Crossing_Delhi_IMD_15Min.csv   PM10 (µg/m³)         114   \n",
      "11    site_104_Burari_Crossing_Delhi_IMD_15Min.csv    NO2 (µg/m³)         127   \n",
      "12    site_104_Burari_Crossing_Delhi_IMD_15Min.csv    SO2 (µg/m³)           1   \n",
      "13    site_104_Burari_Crossing_Delhi_IMD_15Min.csv     CO (mg/m³)          79   \n",
      "14    site_104_Burari_Crossing_Delhi_IMD_15Min.csv  Ozone (µg/m³)          84   \n",
      "15    site_104_Burari_Crossing_Delhi_IMD_15Min.csv    NH3 (µg/m³)           1   \n",
      "16    site_104_Burari_Crossing_Delhi_IMD_15Min.csv        AT (°C)           1   \n",
      "17    site_104_Burari_Crossing_Delhi_IMD_15Min.csv         RH (%)           1   \n",
      "18    site_105_North_Campus_DU_Delhi_IMD_15Min.csv  PM2.5 (µg/m³)         157   \n",
      "19    site_105_North_Campus_DU_Delhi_IMD_15Min.csv   PM10 (µg/m³)         140   \n",
      "\n",
      "    Total Missing Hours  Percent Missing  Gaps_<1hr  Gaps_1-4hr  Gaps_4-8hr  \\\n",
      "0                  2673            10.16          0          64          32   \n",
      "1                  2742            10.42          0          82          11   \n",
      "2                  2702            10.27          0          68          16   \n",
      "3                 26304           100.00          0           0           0   \n",
      "4                  2782            10.58          0          48          21   \n",
      "5                  2632            10.01          0          70          19   \n",
      "6                 26304           100.00          0           0           0   \n",
      "7                 26304           100.00          0           0           0   \n",
      "8                 26304           100.00          0           0           0   \n",
      "9                  1596             6.07          0         101          19   \n",
      "10                 1589             6.04          0          52          13   \n",
      "11                 2789            10.60          0          63          20   \n",
      "12                26304           100.00          0           0           0   \n",
      "13                 1180             4.49          0          30          13   \n",
      "14                 1362             5.18          0          36          12   \n",
      "15                26304           100.00          0           0           0   \n",
      "16                26304           100.00          0           0           0   \n",
      "17                26304           100.00          0           0           0   \n",
      "18                  948             3.60          0         117          14   \n",
      "19                  855             3.25          0         108           7   \n",
      "\n",
      "    Gaps_8hr-1day  Gaps_1-3days  Gaps_3days-1week  Gaps_1-2weeks  \\\n",
      "0              19            11                 1              0   \n",
      "1              23            14                 1              0   \n",
      "2              22            10                 2              0   \n",
      "3               0             0                 0              0   \n",
      "4              28            12                 1              0   \n",
      "5              26             9                 1              0   \n",
      "6               0             0                 0              0   \n",
      "7               0             0                 0              0   \n",
      "8               0             0                 0              0   \n",
      "9              28            16                 1              1   \n",
      "10             29            18                 1              1   \n",
      "11             26            13                 3              1   \n",
      "12              0             0                 0              0   \n",
      "13             23            11                 1              1   \n",
      "14             20            13                 2              1   \n",
      "15              0             0                 0              0   \n",
      "16              0             0                 0              0   \n",
      "17              0             0                 0              0   \n",
      "18             14            12                 0              0   \n",
      "19             14            11                 0              0   \n",
      "\n",
      "    Gaps_2weeks-1month  Gaps_1-3months  Gaps_3months-1year  Gaps_>1year  \n",
      "0                    0               1                   0            0  \n",
      "1                    0               1                   0            0  \n",
      "2                    0               1                   0            0  \n",
      "3                    0               0                   0            1  \n",
      "4                    0               1                   0            0  \n",
      "5                    0               1                   0            0  \n",
      "6                    0               0                   0            1  \n",
      "7                    0               0                   0            1  \n",
      "8                    0               0                   0            1  \n",
      "9                    0               0                   0            0  \n",
      "10                   0               0                   0            0  \n",
      "11                   0               1                   0            0  \n",
      "12                   0               0                   0            1  \n",
      "13                   0               0                   0            0  \n",
      "14                   0               0                   0            0  \n",
      "15                   0               0                   0            1  \n",
      "16                   0               0                   0            1  \n",
      "17                   0               0                   0            1  \n",
      "18                   0               0                   0            0  \n",
      "19                   0               0                   0            0  \n"
     ]
    }
   ],
   "source": [
    "# Create summary dataframe with gap distribution bins\n",
    "summary_data = []\n",
    "\n",
    "# Define the bin labels for columns\n",
    "bin_labels = ['<1hr', '1-4hr', '4-8hr', '8hr-1day', '1-3days', '3days-1week', \n",
    "              '1-2weeks', '2weeks-1month', '1-3months', '3months-1year', '>1year']\n",
    "\n",
    "for site_name, site_data in results.items():\n",
    "    for feature, stats in site_data.items():\n",
    "        row = {\n",
    "            'Site': site_name,\n",
    "            'Feature': feature,\n",
    "            'Total Gaps': stats['total_gaps'],\n",
    "            'Total Missing Hours': stats['total_missing'],\n",
    "            'Percent Missing': round(stats['pct_missing'], 2)\n",
    "        }\n",
    "        \n",
    "        # Add gap distribution bins as columns\n",
    "        gap_dist = stats['gap_distribution']\n",
    "        for bin_label in bin_labels:\n",
    "            row[f'Gaps_{bin_label}'] = gap_dist.get(bin_label, 0)\n",
    "        \n",
    "        summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"Total sites analyzed: {len(results)}\")\n",
    "print(f\"\\nSummary of missing data:\")\n",
    "print(summary_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1bfae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to gap_analysis_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save summary to CSV\n",
    "summary_df.to_csv('/home/rishi/ML Projects/Air Pollution/CPCB/gap_analysis_summary.csv', index=False)\n",
    "print(\"Summary saved to gap_analysis_summary.csv\")\n",
    "\n",
    "# Display gap distribution for a specific site and feature\n",
    "def show_gap_distribution(site_name, feature_name):\n",
    "    \"\"\"Display detailed gap distribution for a specific site and feature\"\"\"\n",
    "    if site_name in results and feature_name in results[site_name]:\n",
    "        stats = results[site_name][feature_name]\n",
    "        print(f\"\\nGap Analysis for {site_name} - {feature_name}\")\n",
    "        print(f\"Total Gaps: {stats['total_gaps']}\")\n",
    "        print(f\"Total Missing Hours: {stats['total_missing']}\")\n",
    "        print(f\"Percent Missing: {stats['pct_missing']:.2f}%\")\n",
    "        print(\"\\nGap Distribution by Duration:\")\n",
    "        for duration, count in sorted(stats['gap_distribution'].items()):\n",
    "            print(f\"  {duration}: {count} gaps\")\n",
    "    else:\n",
    "        print(f\"Data not found for {site_name} - {feature_name}\")\n",
    "\n",
    "# Example usage - uncomment and modify to view specific site/feature\n",
    "# show_gap_distribution('site_113_Shadipur_Delhi_CPCB_15Min.csv', 'PM2.5 (µg/m³)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdda04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site                   site_103_CRRI_Mathura_Road_Delhi_IMD_15Min.csv...\n",
       "Feature                PM2.5 (µg/m³)PM10 (µg/m³)NO2 (µg/m³)SO2 (µg/m³...\n",
       "Total Gaps                                                       1312718\n",
       "Total Missing Hours                                             36626907\n",
       "Percent Missing                                                139245.03\n",
       "Gaps_<1hr                                                              0\n",
       "Gaps_1-4hr                                                        834741\n",
       "Gaps_4-8hr                                                        194011\n",
       "Gaps_8hr-1day                                                     200041\n",
       "Gaps_1-3days                                                       60566\n",
       "Gaps_3days-1week                                                   13320\n",
       "Gaps_1-2weeks                                                       4027\n",
       "Gaps_2weeks-1month                                                  2166\n",
       "Gaps_1-3months                                                      1529\n",
       "Gaps_3months-1year                                                  1459\n",
       "Gaps_>1year                                                          858\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".air_pol_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
