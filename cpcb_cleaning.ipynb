{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b9d5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[pd.NA for i in range(10)]\n",
    "# import numpy as np\n",
    "# s=np.random.randint(1,5,(5,)).tolist()\n",
    "# x=np.random.randint(1,5,(5,)).tolist()\n",
    "# l=s+l+x+l\n",
    "# l=pd.Series(l)\n",
    "# l=pd.to_numeric(l)\n",
    "\n",
    "# l=l.interpolate(method='linear', limit=3, limit_direction='both', limit_area='inside')\n",
    "# l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11637e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean(df, limit_days, feature_threshold):\n",
    "    df['Timestamp']=pd.to_datetime(df['Timestamp'])\n",
    "    df=df.set_index('Timestamp')\n",
    "    start_date=df.index[0]\n",
    "    end_date=df.index[-1]\n",
    "    full_index=pd.date_range(start_date,end_date, freq='1h')\n",
    "    df=df.reindex(full_index)\n",
    "    limit_hours=24*limit_days\n",
    "    df=df.interpolate(method='linear', limit=limit_hours, limit_direction='both', limit_area='inside', axis=0)\n",
    "    df=df.dropna(axis=0, how='all')\n",
    "    num_rows=df.shape[0]\n",
    "    feature_present_fraction=df.notnull().sum(axis=0)/num_rows\n",
    "    df = df.drop(columns=feature_present_fraction[feature_present_fraction < feature_threshold].index)\n",
    "    df= df.dropna(axis=0, how='any')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7654b8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140256, 25)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"/home/rishi/ML Projects/Air Pollution/sites_comb/site_113_Shadipur_Delhi_CPCB_15Min.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f17cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=clean(df,limit_days=7, feature_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a35f9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "x.to_csv(\"x_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c74375dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80650, 15)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c77c041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_gaps(df):\n",
    "    time_diffs = df.index.to_series().diff()\n",
    "    expected_freq = pd.Timedelta(hours=1)\n",
    "    is_gap = time_diffs > expected_freq\n",
    "    group_ids = is_gap.cumsum()\n",
    "\n",
    "    # Calculate duration for each group using agg\n",
    "    group_durations = df.groupby(group_ids).apply(\n",
    "        lambda g: (g.index.max() - g.index.min()).total_seconds() / (24 * 3600),\n",
    "    )\n",
    "    \n",
    "    value_counts = group_durations.value_counts().sort_index()\n",
    "    \n",
    "    return value_counts, sum(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36427606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.500000       1\n",
       " 8.791667       1\n",
       " 14.000000      5\n",
       " 14.041667      2\n",
       " 14.083333      1\n",
       " 14.125000      1\n",
       " 14.166667      1\n",
       " 14.291667      1\n",
       " 15.458333      1\n",
       " 22.083333      1\n",
       " 22.625000      1\n",
       " 23.791667      1\n",
       " 26.125000      1\n",
       " 34.291667      1\n",
       " 36.250000      1\n",
       " 41.083333      1\n",
       " 42.166667      1\n",
       " 50.625000      1\n",
       " 56.416667      1\n",
       " 65.750000      1\n",
       " 68.250000      1\n",
       " 70.916667      1\n",
       " 72.625000      1\n",
       " 80.000000      1\n",
       " 82.541667      1\n",
       " 84.000000      1\n",
       " 100.291667     1\n",
       " 103.083333     1\n",
       " 103.958333     1\n",
       " 116.875000     1\n",
       " 125.541667     1\n",
       " 182.750000     1\n",
       " 312.833333     1\n",
       " 1250.416667    1\n",
       " Name: count, dtype: int64,\n",
       " 39)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=num_gaps(x)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5824b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_gaps(df):\n",
    "    time_diffs = df.index.to_series().diff()\n",
    "    expected_freq = pd.Timedelta(hours=1)\n",
    "    is_gap = time_diffs > expected_freq\n",
    "    group_ids = is_gap.cumsum()\n",
    "\n",
    "    # Calculate duration for each group using agg\n",
    "    group_durations = df.groupby(group_ids).apply(\n",
    "        lambda g: (g.index.max() - g.index.min()).total_seconds() / (24 * 3600),\n",
    "    )\n",
    "    \n",
    "    value_counts = group_durations.value_counts().sort_index()\n",
    "    \n",
    "    return value_counts, sum(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f498c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_contiguous_series(df, file_name):\n",
    "    # Create folder with the file_name\n",
    "    os.makedirs(file_name, exist_ok=True)\n",
    "    \n",
    "    # Identify gaps and create group IDs\n",
    "    time_diffs = df.index.to_series().diff()\n",
    "    expected_freq = pd.Timedelta(hours=1)\n",
    "    is_gap = time_diffs > expected_freq\n",
    "    group_ids = is_gap.cumsum()\n",
    "    \n",
    "    # Save each contiguous group\n",
    "    for group_id, group_df in df.groupby(group_ids):\n",
    "        start_time = group_df.index.min().strftime('%Y%m%d_%H%M%S')\n",
    "        end_time = group_df.index.max().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Reset index and put timestamp in 'Timestamp' column\n",
    "        group_df_reset = group_df.reset_index()\n",
    "        group_df_reset.rename(columns={'index': 'Timestamp'}, inplace=True)\n",
    "        \n",
    "        output_filename = f\"{file_name}/{file_name}_{start_time}_to_{end_time}.csv\"\n",
    "        group_df_reset.to_csv(output_filename, index=False)\n",
    "        \n",
    "    print(f\"Saved {len(df.groupby(group_ids))} contiguous series to folder '{file_name}/'\")\n",
    "    \n",
    "    return len(df.groupby(group_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b12ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 39 contiguous series to folder 'temp_split/'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_contiguous_series(x, \"temp_split\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".air_pol_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
